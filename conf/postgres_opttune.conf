[PostgreSQL]
pgbin = /usr/pgsql-12/bin # PostgreSQL bin PATH
pgdata = /var/lib/pgsql/12/data  # PostgreSQL database cluster directory path
major_version = 12 # PostgreSQL major version
pghost = localhost # PostgreSQL server host.
# Note: If you use remote PostgreSQL for pghost,
# pgbin is used by both PostgreSQL server and postgres_opttune server.
# Therefore, the PostgreSQL installation directory of the PostgreSQL server and
# the postgres_opttune server must be the same.
# (If they are different, please use symbolic links to match them.)
pgport = 5432 # PostgreSQL server port
pguser = postgres # PostgreSQL user name(Database user)
pgpassword = postgres12 # PostgreSQL user password(Database user)
pgdatabase = tpcc # PostgreSQL Database
pg_os_user = postgres # PostgrSQL ower user(OS user)
# When tuning remote PostgreSQL, use an SSH connection to restart PostgreSQL or clear the cache.
# Note: When using remote PostgreSQL, it is necessary to grant sudo permission without password to the remote os user.
ssh_port = 22 # ssh port
ssh_password = postgres # pg_os_user's ssh password

[workload-sampling]
workload_sampling_time_second = 300
# Time (in seconds) to sample the workload running on the database in the [PostgreSQL] section
my_workload_save_dir = ./workload_data/
# Workload save database settings
pghost = localhost # PostgreSQL server host
pgport = 5432 # PostgreSQL server port
pguser = postgres # PostgreSQL user name(Database user)
pgpassword = postgres12 # PostgreSQL user password(Database user)
pgdatabase = sampling # PostgreSQL Database
# workload save directory


[turning]
study_name = pgbench_study # study name
required_recovery_time_second = 0
# The maximum recovery time allowed by the user in case of a PostgreSQL crash,
# which is used to estimate the wax_wal_size parameter.
# Note: The default value of 0 does not perform the estimation of the wax_wal_size parameter.
benchmark =  pgbench # Benchmark tool name('my_workload' or pgbench' or 'oltpbench' or 'star_schema_benchmark')
parameter_json_dir = ./conf/
number_trail = 100 # Number of benchmarks to run for turning
data_load_interval = 10 # Specify the data load interval by the number of benchmarks
sample_mode = TPE # Sampling mode(TPE, RandomSampler, SkoptSampler, CmaEsSampler)
debug = False # debug mode
save_study_history = True # Whether to save study history
load_study_history = True # Whether to load study history if a study name already exists.
history_database_url = sqlite:///study-history.db   # Example PostgreSQL. postgresql://postgres@localhost/study_history

[my-workload]
my_workload_save_file = workload_data/2020-07-05_180647.531417-2020-07-05_180657.531661.pkl
# File saved using workload_sampler.py

[pgbench]
scale_factor = 10 # pgbench scale factor
clients = 10 # Number of clients
evaluation_time = 300 # time of benchmark run

[oltpbench]
oltpbench_path = /opt/oltpbench # Oltpbenchmark directory path
benchmark_kind = tpcc # Benchmark kind name
oltpbench_config_path = ./conf/tpcc_config_postgres.xml # config path

[star-schema-benchmark]
ssb_dbgen_path = /opt/ssb-dbgen # ssb-dbgen directory path
scale_factor = 1 # ssb-dbgen sacle factor
clients = 1 # Number of clients
# Note: At the moment, only support 1.
# If two or more are specified, multiple clients will execute the same SQL.
sql_file_path = ./pgopttune/workload/star_schema_sql/
sql_key = Q1.1, Q2.1, Q3.1
# List of queries to be executed by the client (comma-separated)
# Please specify the name of the file in pgopttune/workload/star_schema_sql/ directory(sql_file_path parameter diretory)
# (e.g., Q1.1,Q2,1).